import os
import json
import time
import streamlit as st
from datetime import datetime, date

from models import AudioTranscriptionChunk, USE_VECTOR, VECTOR_BACKEND, get_db, RAGChatLog
from services.rag import highlight_date_in_query
from services.rag_service import get_rag_service


def run_rag_tab():
    st.header("RAGæ¤œç´¢ï¼ˆæ–‡å­—èµ·ã“ã—QAï¼‰")

    rag_service = get_rag_service()

    if not rag_service.enabled:
        if not USE_VECTOR:
            st.warning(
                "RAGæ©Ÿèƒ½ã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ Turso(libSQL) ã®ãƒ™ã‚¯ãƒˆãƒ«å¯¾å¿œãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹æˆã—ã€"
                "audio_transcription_chunks ã« libsql_vector_idx ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼ˆè‡ªå‹•ä½œæˆæ¸ˆã¿ã§ãªã„å ´åˆï¼‰ã€‚"
            )
            st.info("ãƒ­ãƒ¼ã‚«ãƒ«ã®é€šå¸¸SQLiteã§ã¯RAGã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚Tursoã® `sqlite+libsql://` ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.warning(
                "OPENAI_API_KEY ãŒæœªè¨­å®šã€ã‚‚ã—ãã¯åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«è¨­å®šã«å•é¡ŒãŒã‚ã‚‹ãŸã‚RAGãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚"
            )
            st.info("ç’°å¢ƒå¤‰æ•°ã«OPENAI_API_KEYã‚’è¨­å®šã—ã€å¿…è¦ã«å¿œã˜ã¦ EMBEDDING_MODEL / EMBEDDING_DIM ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
        return

    if "rag_history" not in st.session_state:
        st.session_state.rag_history = []

    # æ¤œç´¢ã¯å¸¸ã«å…¨ãƒ‡ãƒ¼ã‚¿å¯¾è±¡ï¼ˆãƒ™ã‚¯ãƒˆãƒ«/FTSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯å…¨ä½“ã‹ã‚‰ä¸Šä½ã‚’è¿”ã™ï¼‰ã€‚
    # å€™è£œå–å¾—ä»¶æ•°ï¼ˆtop_kï¼‰ã¯å†…éƒ¨æ—¢å®šå€¤ã§å›ºå®šã—ã€UIã§ã¯éžè¡¨ç¤ºã€‚
    st.caption("æ¤œç´¢ã¯å…¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸Šä½å€™è£œã‚’è‡ªå‹•æŠ½å‡ºã—ã¾ã™ï¼ˆè¨­å®šä¸è¦ï¼‰ã€‚å®Ÿè¡Œä¸­ã«ã‚¿ãƒ–ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã¨å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚")

    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    default_alpha = float(os.getenv("RAG_HYBRID_ALPHA", "0.6"))
    cols = st.columns([1, 1, 1])
    with cols[0]:
        if st.button("å±¥æ­´ã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
            st.session_state.rag_history = []
            st.rerun()
    with cols[1]:
        use_hybrid = st.checkbox(
            "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’æœ‰åŠ¹åŒ– (FTSÃ—ãƒ™ã‚¯ãƒˆãƒ«)",
            value=True,
            help=(
                "FTSï¼ˆå…¨æ–‡æ¤œç´¢ï¼‰ã¨ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’ä½µç”¨ã—ã€ä¸¡è€…ã®ã‚¹ã‚³ã‚¢ã‚’é‡ã¿ä»˜ãã§çµ±åˆã—ã¾ã™ã€‚\n"
                "libSQLã§ã¯FTS5ã®ä»®æƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå¿…è¦ã§ã™ï¼ˆè‡ªå‹•ä½œæˆæ¸ˆã¿ï¼‰ã€‚"
            ),
        )
    with cols[2]:
        alpha = st.slider(
            "ãƒ™ã‚¯ãƒˆãƒ«é‡ã¿ Î±",
            min_value=0.0,
            max_value=1.0,
            value=default_alpha,
            step=0.05,
            help="1.0ã§ãƒ™ã‚¯ãƒˆãƒ«ã®ã¿ã€0.0ã§FTSã®ã¿ã€‚æ—¢å®šã¯0.6ã€‚",
        )
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã¯å¸¸ã«æœ‰åŠ¹
    # å›žç­”ã«ä½¿ã†ãƒãƒ£ãƒ³ã‚¯ä¸Šé™ã¯å†…éƒ¨æ—¢å®šå€¤ï¼ˆRAG_CONTEXT_MAX_CHUNKSï¼‰ã§å›ºå®šã€‚UIã§ã¯éžè¡¨ç¤ºã€‚
    context_k = None

    for message in st.session_state.rag_history:
        block = st.chat_message(message["role"])
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯æ—¥ä»˜ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        if message["role"] == "user":
            block.markdown(highlight_date_in_query(message["content"]))
        else:
            block.markdown(message["content"])
        if message["role"] == "assistant" and message.get("contexts"):
            with block.expander("å‚ç…§ã—ãŸãƒãƒ£ãƒ³ã‚¯", expanded=False):
                for idx, ctx in enumerate(message["contexts"], start=1):
                    st.markdown(
                        f"**{idx}. ã‚¹ã‚³ã‚¢:** {ctx['score']:.3f}"
                        f" / **ãƒ•ã‚¡ã‚¤ãƒ«:** {ctx.get('file_path') or '-'}"
                        f" / **ã‚¿ã‚°:** {ctx.get('tag') or '-'}"
                    )
                    if ctx.get("recorded_at"):
                        st.caption(f"éŒ²éŸ³æ™‚åˆ»: {ctx['recorded_at']}")
                    st.write(ctx["chunk_text"])
                    st.divider()

    query = st.chat_input("æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿ã¸ã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: ã€Œæ˜¨æ—¥ã®ä¼šè­°ã«ã¤ã„ã¦ã€ã€Œ12æœˆ3æ—¥ã®æ‰“ã¡åˆã‚ã›å†…å®¹ã€ï¼‰")

    if query:
        st.session_state.rag_history.append({"role": "user", "content": query})
        # æ—¥ä»˜éƒ¨åˆ†ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¦è¡¨ç¤º
        st.chat_message("user").markdown(highlight_date_in_query(query))

        # ä¼šè©±å±¥æ­´ã‚’æ§‹ç¯‰ï¼ˆç¾åœ¨ã®è³ªå•ã¯é™¤å¤–ï¼‰
        chat_history_for_rag = [
            {"role": msg["role"], "content": msg["content"]}
            for msg in st.session_state.rag_history[:-1]  # æœ€å¾Œã®è³ªå•ã¯é™¤å¤–
            if msg["role"] in ("user", "assistant") and msg.get("content")
        ]

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œã®ã¿
        with st.spinner("æ¤œç´¢ã‚’å®Ÿè¡Œä¸­..."):
            db = next(get_db())
            try:
                result2 = rag_service.answer_stream(
                    db,
                    query,
                    top_k=None,
                    hybrid=use_hybrid,
                    alpha=alpha,
                    context_k=context_k,
                    chat_history=chat_history_for_rag,
                )
            finally:
                db.close()

        matches = result2.get("matches", [])
        meta = result2.get("meta") or {}
        stream_fn = result2.get("stream_fn")

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º
        with st.chat_message("assistant"):
            tgen0 = time.time()
            try:
                full_text = st.write_stream(stream_fn()) if callable(stream_fn) else ""
            except Exception:
                acc = ""
                placeholder = st.empty()
                try:
                    for chunk in (stream_fn() if callable(stream_fn) else []):
                        acc += str(chunk)
                        placeholder.markdown(acc)
                except Exception:
                    acc = "[ã‚¨ãƒ©ãƒ¼] å‡ºåŠ›ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
                    placeholder.markdown(acc)
                full_text = acc
            tgen1 = time.time()

            # å‚ç…§ãƒãƒ£ãƒ³ã‚¯è¡¨ç¤º
            if matches:
                with st.expander("å‚ç…§ã—ãŸãƒãƒ£ãƒ³ã‚¯", expanded=False):
                    for idx, ctx in enumerate(matches, start=1):
                        st.markdown(
                            f"**{idx}. ç·åˆã‚¹ã‚³ã‚¢:** {ctx['score']:.3f}"
                            f" / **ãƒ•ã‚¡ã‚¤ãƒ«:** {ctx.get('file_path') or '-'}"
                            f" / **ã‚¿ã‚°:** {ctx.get('tag') or '-'}"
                        )
                        if ctx.get("recorded_at"):
                            st.caption(f"éŒ²éŸ³æ™‚åˆ»: {ctx['recorded_at']}")
                        sv = ctx.get("score_vector")
                        sf = ctx.get("score_fts")
                        if sv is not None or sf is not None:
                            st.caption(
                                f"ãƒ™ã‚¯ãƒˆãƒ«: {sv if sv is not None else '-'} / FTS: {sf if sf is not None else '-'}"
                            )
                        st.write(ctx["chunk_text"])
                        st.divider()

        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ã®è­¦å‘Šè¡¨ç¤º
        date_filter = meta.get("date_filter")
        if meta.get("date_no_match") and date_filter:
            st.warning(
                f"âš ï¸ æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜ï¼ˆ{date_filter.get('start')}ï¼‰ã«è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
                f"ä»¥ä¸‹ã¯æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãªã—ã®æ¤œç´¢çµæžœã§ã™ã€‚"
            )

        # ãƒ¡ã‚¿æƒ…å ±ï¼ˆç§’å˜ä½ï¼‰
        timings = (meta.get("timings_ms") or {}) if isinstance(meta, dict) else {}
        retrieval_s = (timings.get("retrieval") or 0) / 1000.0
        prompt_s = (timings.get("prompt_build") or 0) / 1000.0
        gen_s = (tgen1 - tgen0)
        total_s = retrieval_s + prompt_s + gen_s
        cap = f"å€™è£œ: {meta.get('candidates')} / ä½¿ç”¨: {meta.get('used_context_chunks')} ä»¶"
        cap += f" / æ¤œç´¢: {retrieval_s:.3f}s / ç”Ÿæˆ: {gen_s:.3f}s / åˆè¨ˆ: {total_s:.3f}s"
        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿æƒ…å ±
        if date_filter:
            cap += f" / ðŸ“… æ—¥ä»˜: {date_filter.get('start')}"
            if date_filter.get('start') != date_filter.get('end'):
                cap += f" ã€œ {date_filter.get('end')}"
            if meta.get("date_filtered"):
                cap += " âœ“"
            elif meta.get("date_no_match"):
                cap += " (è©²å½“ãªã—)"
        st.caption(cap)

        # å±¥æ­´ãƒ»DBä¿å­˜
        st.session_state.rag_history.append(
            {"role": "assistant", "content": full_text, "contexts": matches}
        )

        def _json_default(o):
            if isinstance(o, (datetime, date)):
                return o.isoformat()
            return str(o)

        contexts_json = json.loads(json.dumps(matches, default=_json_default))

        with st.spinner("ãƒãƒ£ãƒƒãƒˆã‚’ä¿å­˜ä¸­..."):
            db2 = next(get_db())
            try:
                log = RAGChatLog(
                    user_text=query,
                    answer_text=full_text,
                    contexts=contexts_json,
                    used_hybrid=bool(use_hybrid),
                    alpha=float(alpha) if alpha is not None else None,
                )
                db2.add(log)
                db2.commit()
            except Exception:
                db2.rollback()
                st.warning("ãƒãƒ£ãƒƒãƒˆã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
            finally:
                db2.close()

    # --- éŽåŽ»ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ï¼ˆç›´è¿‘ï¼‰ ---
    st.divider()
    st.subheader("éŽåŽ»ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´")

    colh1, colh2, colh3 = st.columns([2, 1, 1])
    with colh1:
        kw = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆè³ªå•/å›žç­”ã‚’å¯¾è±¡ï¼‰", value="", placeholder="ä¾‹: å¥‘ç´„ æœŸé™" )
    with colh2:
        limit = st.slider("è¡¨ç¤ºä»¶æ•°", min_value=5, max_value=100, value=20, step=5)
    with colh3:
        hybrid_filter = st.selectbox("ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰",
                                     options=["ã™ã¹ã¦", "ON", "OFF"], index=0)

    dbh = next(get_db())
    try:
        q = dbh.query(RAGChatLog).order_by(RAGChatLog.created_at.desc())
        if kw:
            from sqlalchemy import or_
            q = q.filter(
                or_(
                    RAGChatLog.user_text.contains(kw),
                    RAGChatLog.answer_text.contains(kw),
                )
            )
        if hybrid_filter == "ON":
            q = q.filter(RAGChatLog.used_hybrid.is_(True))
        elif hybrid_filter == "OFF":
            q = q.filter(RAGChatLog.used_hybrid.is_(False))

        logs = q.limit(limit).all()
    finally:
        dbh.close()

    if not logs:
        st.info("ä¿å­˜ã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚æ¤œç´¢/è³ªå•å¾Œã«ã“ã“ã¸è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    else:
        for log in logs:
            with st.expander(
                f"[{log.created_at}] è³ªå•: { (log.user_text or '')[:40] + ('â€¦' if log.user_text and len(log.user_text) > 40 else '') }",
                expanded=False,
            ):
                st.markdown("**è³ªå•**")
                st.write(log.user_text or "")
                st.markdown("**å›žç­”**")
                st.write(log.answer_text or "")
                st.caption(
                    f"ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰: {'ON' if log.used_hybrid else 'OFF'} / Î±: {log.alpha if log.alpha is not None else '-'}"
                )
                ctxs = log.contexts or []
                if ctxs:
                    st.markdown("**å‚ç…§ã—ãŸãƒãƒ£ãƒ³ã‚¯ï¼ˆæœ€å¤§3ä»¶ã‚’è¡¨ç¤ºï¼‰**")
                    for idx, ctx in enumerate(ctxs[:3], start=1):
                        st.markdown(
                            f"- {idx}. ã‚¹ã‚³ã‚¢: {ctx.get('score', '-')}; ãƒ•ã‚¡ã‚¤ãƒ«: {ctx.get('file_path','-')}; ã‚¿ã‚°: {ctx.get('tag','-')}"
                        )
                        if ctx.get("recorded_at"):
                            st.caption(f"éŒ²éŸ³æ™‚åˆ»: {ctx['recorded_at']}")
                        snippet = (ctx.get("chunk_text") or "")
                        st.text(snippet[:200] + ("â€¦" if len(snippet) > 200 else ""))
