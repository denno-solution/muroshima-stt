import streamlit as st
import pandas as pd
from pathlib import Path
import tempfile
import os
from datetime import datetime
import json
import librosa
import soundfile as sf
from dotenv import load_dotenv
import logging

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

from models import AudioTranscription, get_db
from stt_wrapper import STTModelWrapper
from text_structurer import TextStructurer
from env_watcher import check_env_changes, display_env_status
from app_settings import AppSettings
from auth import check_password, logout
from semantic_search import get_semantic_search_engine
from rag_qa import get_rag_qa_system

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
log_dir = Path(__file__).parent.parent / "logs"
log_dir.mkdir(exist_ok=True)

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
file_handler = logging.FileHandler(log_dir / "streamlit_app.log", encoding='utf-8')
file_handler.setLevel(logging.DEBUG)

# ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)

logger.addHandler(file_handler)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="éŸ³å£°æ–‡å­—èµ·ã“ã—Webã‚¢ãƒ—ãƒª",
    page_icon="ğŸ™ï¸",
    layout="wide"
)

# ç’°å¢ƒå¤‰æ•°ã®å¤‰æ›´ã‚’ãƒã‚§ãƒƒã‚¯
check_env_changes()

# ã‚¢ãƒ—ãƒªè¨­å®šã®åˆæœŸåŒ–
settings = AppSettings()

# Basicèªè¨¼ãƒã‚§ãƒƒã‚¯
if not check_password():
    st.stop()

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ™ï¸ éŸ³å£°æ–‡å­—èµ·ã“ã—Webã‚¢ãƒ—ãƒª")
st.markdown("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€æ–‡å­—èµ·ã“ã—ã¨æ§‹é€ åŒ–ã‚’è¡Œã„ã¾ã™ã€‚")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "transcriptions" not in st.session_state:
    st.session_state.transcriptions = []
if "processing" not in st.session_state:
    st.session_state.processing = False
if "mic_processing" not in st.session_state:
    st.session_state.mic_processing = False
if "mic_audio_bytes" not in st.session_state:
    st.session_state.mic_audio_bytes = None
if "settings" not in st.session_state:
    st.session_state.settings = settings

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šè¨­å®š
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    # STTãƒ¢ãƒ‡ãƒ«é¸æŠ
    available_models = STTModelWrapper.get_available_models()
    
    # ä¿å­˜ã•ã‚ŒãŸé¸æŠã‚’å–å¾—ã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
    saved_model = settings.get_selected_stt_model()
    default_index = 4  # ElevenLabsã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«è¨­å®š
    if saved_model and saved_model in available_models:
        default_index = available_models.index(saved_model)
    
    selected_model = st.selectbox(
        "STTãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
        available_models,
        index=default_index,
        help="ä½¿ç”¨ã™ã‚‹éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
    )
    
    # é¸æŠãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ä¿å­˜
    if selected_model != saved_model:
        settings.set_selected_stt_model(selected_model)
        logger.info(f"STTãƒ¢ãƒ‡ãƒ«ã®é¸æŠã‚’ä¿å­˜: {selected_model}")
    
    # é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«ã®è¦ä»¶ãƒã‚§ãƒƒã‚¯
    try:
        wrapper = STTModelWrapper(selected_model)
        requirements = wrapper.check_requirements()
        
        if requirements:
            st.subheader("ç’°å¢ƒå¤‰æ•°ã®è¨­å®šçŠ¶æ³")
            for key, is_set in requirements.items():
                if is_set:
                    st.success(f"âœ… {key}")
                else:
                    st.error(f"âŒ {key} ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    st.divider()
    
    # æ§‹é€ åŒ–è¨­å®š
    st.subheader("æ§‹é€ åŒ–è¨­å®š")
    use_structuring = st.checkbox(
        "Gemini Flash 2.5-liteã§è‡ªå‹•æ§‹é€ åŒ–", 
        value=settings.get_use_structuring()
    )
    
    # è¨­å®šãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ä¿å­˜
    if use_structuring != settings.get_use_structuring():
        settings.set_use_structuring(use_structuring)
        logger.info(f"æ§‹é€ åŒ–è¨­å®šã‚’ä¿å­˜: {use_structuring}")
    
    if use_structuring:
        gemini_key_set = bool(os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_AI_API_KEY"))
        if gemini_key_set:
            st.success("âœ… Gemini API ã‚­ãƒ¼è¨­å®šæ¸ˆã¿")
        else:
            st.error("âŒ GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    st.divider()
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
    st.subheader("ğŸ› ãƒ‡ãƒãƒƒã‚°è¨­å®š")
    debug_mode = st.checkbox(
        "ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–", 
        value=settings.get_debug_mode()
    )
    
    # è¨­å®šãŒå¤‰æ›´ã•ã‚ŒãŸã‚‰ä¿å­˜
    if debug_mode != settings.get_debug_mode():
        settings.set_debug_mode(debug_mode)
        logger.info(f"ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰è¨­å®šã‚’ä¿å­˜: {debug_mode}")
    
    if debug_mode:
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤º
        if st.button("ğŸ“‹ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º"):
            log_files = {
                "Streamlitãƒ­ã‚°": log_dir / "streamlit_app.log",
                "ElevenLabsãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°": log_dir / "elevenlabs_debug.log"
            }
            
            for log_name, log_path in log_files.items():
                if log_path.exists():
                    st.subheader(f"ğŸ“„ {log_name}")
                    try:
                        with open(log_path, "r", encoding="utf-8") as f:
                            # æœ€æ–°ã®50è¡Œã‚’è¡¨ç¤º
                            lines = f.readlines()
                            recent_lines = lines[-50:] if len(lines) > 50 else lines
                            st.code("".join(recent_lines), language="log")
                    except Exception as e:
                        st.error(f"ãƒ­ã‚°èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    st.info(f"{log_name}ã¯ã¾ã å­˜åœ¨ã—ã¾ã›ã‚“")
    
    st.divider()
    
    # ç’°å¢ƒå¤‰æ•°ã®çŠ¶æ…‹è¡¨ç¤º
    display_env_status(sidebar=True)
    
    # ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³ï¼ˆBasicèªè¨¼ãŒæœ‰åŠ¹ãªå ´åˆã®ã¿è¡¨ç¤ºï¼‰
    if os.getenv("BASIC_AUTH_USERNAME") and os.getenv("BASIC_AUTH_PASSWORD"):
        st.divider()
        if st.button("ğŸšª ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ", type="secondary", use_container_width=True):
            logout()
            st.rerun()

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“¤ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ™ï¸ ãƒã‚¤ã‚¯éŒ²éŸ³", "ğŸ“Š å‡¦ç†çµæœ", "ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"])

with tab1:
    st.header("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
    uploaded_files = st.file_uploader(
        "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=["wav", "mp3", "m4a", "flac", "ogg"],
        accept_multiple_files=True,
        help="è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒæ™‚ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™"
    )
    
    if uploaded_files:
        st.success(f"{len(uploaded_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±è¡¨ç¤º
        file_info = []
        for file in uploaded_files:
            file_info.append({
                "ãƒ•ã‚¡ã‚¤ãƒ«å": file.name,
                "ã‚µã‚¤ã‚º": f"{file.size / 1024:.1f} KB",
                "ã‚¿ã‚¤ãƒ—": file.type
            })
        
        df_files = pd.DataFrame(file_info)
        st.dataframe(df_files, use_container_width=True)
        
        # å‡¦ç†é–‹å§‹ãƒœã‚¿ãƒ³
        if st.button("ğŸš€ æ–‡å­—èµ·ã“ã—é–‹å§‹", type="primary", use_container_width=True, disabled=st.session_state.processing):
            st.session_state.processing = True
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # STTãƒ¢ãƒ‡ãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆæ§‹é€ åŒ–ã®åˆæœŸåŒ–
            try:
                stt_wrapper = STTModelWrapper(selected_model)
                text_structurer = TextStructurer() if use_structuring else None
            except Exception as e:
                st.error(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                st.session_state.processing = False
                st.stop()
            
            # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
            for idx, uploaded_file in enumerate(uploaded_files):
                status_text.text(f"å‡¦ç†ä¸­: {uploaded_file.name} ({idx + 1}/{len(uploaded_files)})")
                progress_bar.progress((idx + 1) / len(uploaded_files))
                
                try:
                    logger.info(f"å‡¦ç†é–‹å§‹: {uploaded_file.name}")
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                    with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                        tmp_file.write(uploaded_file.getvalue())
                        tmp_path = tmp_file.name
                    
                    logger.debug(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: {tmp_path}")
                    
                    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±å–å¾—
                    audio_data, sr = librosa.load(tmp_path, sr=None)
                    duration = len(audio_data) / sr
                    logger.debug(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±: æ™‚é–“={duration:.2f}ç§’, ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ={sr}Hz")
                    
                    # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
                    logger.info(f"æ–‡å­—èµ·ã“ã—å®Ÿè¡Œä¸­: {uploaded_file.name} (ãƒ¢ãƒ‡ãƒ«: {selected_model})")
                    transcription = stt_wrapper.transcribe(tmp_path)
                    
                    # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å«ã‚€ã‚¿ãƒ—ãƒ«ã‹ãƒã‚§ãƒƒã‚¯
                    error_msg = None
                    if isinstance(transcription, tuple) and transcription[0] is None:
                        error_msg = transcription[1]
                        transcription = None
                        logger.error(f"æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {error_msg}")
                    
                    if transcription:
                        # æ§‹é€ åŒ–å‡¦ç†
                        structured_data = None
                        tags = "æœªåˆ†é¡"
                        
                        if use_structuring and text_structurer:
                            structured_data = text_structurer.structure_text(transcription)
                            if structured_data:
                                tags = text_structurer.extract_tags(structured_data)
                        
                        # çµæœã‚’ä¿å­˜
                        result = {
                            "ãƒ•ã‚¡ã‚¤ãƒ«å": uploaded_file.name,
                            "éŒ²éŸ³æ™‚åˆ»": datetime.now(),
                            "éŒ²éŸ³æ™‚é–“": duration,
                            "æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ": transcription,
                            "æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿": structured_data,
                            "ã‚¿ã‚°": tags,
                            "ç™ºè¨€äººæ•°": 1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                        }
                        
                        st.session_state.transcriptions.append(result)
                        
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                        db = next(get_db())
                        try:
                            audio_record = AudioTranscription(
                                éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«path=uploaded_file.name,
                                ç™ºè¨€äººæ•°=1,
                                éŒ²éŸ³æ™‚åˆ»=datetime.now(),
                                éŒ²éŸ³æ™‚é–“=duration,
                                æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ=transcription,
                                æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿=structured_data,
                                ã‚¿ã‚°=tags
                            )
                            db.add(audio_record)
                            db.commit()
                            
                            # ãƒ™ã‚¯ãƒˆãƒ«DBã«è¿½åŠ 
                            try:
                                search_engine = get_semantic_search_engine()
                                doc_id = f"audio_{audio_record.éŸ³å£°ID}"
                                metadata = {
                                    "audio_id": audio_record.éŸ³å£°ID,
                                    "file_path": uploaded_file.name,
                                    "recording_time": audio_record.éŒ²éŸ³æ™‚åˆ».isoformat(),
                                    "duration": duration,
                                    "speakers": 1,
                                    "tags": tags or ""
                                }
                                if structured_data:
                                    metadata["structured_data"] = str(structured_data)
                                
                                search_engine.add_document(doc_id, transcription, metadata)
                                logger.info(f"Added to vector DB: {doc_id}")
                            except Exception as e:
                                logger.warning(f"Failed to add to vector DB: {str(e)}")
                                
                        finally:
                            db.close()
                    else:
                        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚‹å ´åˆã¯è©³ç´°ã‚’è¡¨ç¤º
                        if error_msg:
                            st.error(f"âŒ {uploaded_file.name} ã®æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                            st.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {error_msg}")
                            logger.error(f"æ–‡å­—èµ·ã“ã—å¤±æ•—: {uploaded_file.name}, ã‚¨ãƒ©ãƒ¼: {error_msg}")
                        else:
                            st.error(f"âŒ {uploaded_file.name} ã®æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆçµæœãŒç©ºï¼‰")
                            logger.error(f"æ–‡å­—èµ·ã“ã—å¤±æ•—: {uploaded_file.name}, çµæœãŒç©º")
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    os.unlink(tmp_path)
                    logger.debug(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {tmp_path}")
                    
                except Exception as e:
                    error_msg = f"å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({uploaded_file.name}): {str(e)}"
                    st.error(error_msg)
                    logger.error(error_msg, exc_info=True)
            
            progress_bar.progress(1.0)
            status_text.text("âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            st.session_state.processing = False
            st.rerun()

with tab2:
    st.header("ãƒã‚¤ã‚¯éŒ²éŸ³")
    
    st.markdown("**ãƒã‚¤ã‚¯ã‹ã‚‰ç›´æ¥éŸ³å£°ã‚’éŒ²éŸ³ã—ã¦æ–‡å­—èµ·ã“ã—ã—ã¾ã™**")
    
    # éŒ²éŸ³æ©Ÿèƒ½
    audio_bytes = st.audio_input("ğŸ™ï¸ ãƒã‚¤ã‚¯ã§éŒ²éŸ³ã—ã¦ãã ã•ã„", help="éŒ²éŸ³ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦éŸ³å£°ã‚’éŒ²éŸ³ã—ã€åœæ­¢ãƒœã‚¿ãƒ³ã§éŒ²éŸ³ã‚’çµ‚äº†ã—ã¦ãã ã•ã„")
    
    if audio_bytes:
        # æ–°ã—ã„éŒ²éŸ³ãŒã‚ã‚Œã°ä¿å­˜
        if audio_bytes != st.session_state.mic_audio_bytes:
            st.session_state.mic_audio_bytes = audio_bytes
            st.session_state.mic_processing = False
        
        st.success("éŒ²éŸ³å®Œäº†ï¼")
        
        # ç¢ºèªãƒ€ã‚¤ã‚¢ãƒ­ã‚°
        if not st.session_state.mic_processing:
            if st.button("ğŸš€ æ–‡å­—èµ·ã“ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã™ã‹ï¼Ÿ", type="primary", key="mic_process_button"):
                st.session_state.mic_processing = True
                st.rerun()
        
        # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
        if st.session_state.mic_processing:
            try:
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                with tempfile.NamedTemporaryFile(delete=False, suffix='.webm') as tmp_file:
                    # audio_bytesãŒUploadedFileã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆã¯getvalue()ã§ãƒã‚¤ãƒˆåˆ—ã‚’å–å¾—
                    if hasattr(audio_bytes, 'getvalue'):
                        tmp_file.write(audio_bytes.getvalue())
                    else:
                        tmp_file.write(audio_bytes)
                    tmp_path = tmp_file.name
                
                logger.info(f"ãƒã‚¤ã‚¯éŒ²éŸ³å‡¦ç†é–‹å§‹: {tmp_path}")
                
                # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±å–å¾—
                try:
                    audio_data, sr = librosa.load(tmp_path, sr=None)
                    duration = len(audio_data) / sr
                    logger.debug(f"éŒ²éŸ³éŸ³å£°æƒ…å ±: æ™‚é–“={duration:.2f}ç§’, ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ={sr}Hz")
                except Exception as e:
                    # librosaã§èª­ã¿è¾¼ã‚ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    duration = 0.0
                    logger.warning(f"éŸ³å£°æƒ…å ±å–å¾—å¤±æ•—ï¼ˆå‡¦ç†ã¯ç¶™ç¶šï¼‰: {e}")
                
                # STTãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
                stt_wrapper = STTModelWrapper(selected_model)
                text_structurer = TextStructurer() if use_structuring else None
                
                # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
                with st.spinner("æ–‡å­—èµ·ã“ã—ä¸­..."):
                    transcription = stt_wrapper.transcribe(tmp_path)
                    
                    # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å«ã‚€ã‚¿ãƒ—ãƒ«ã‹ãƒã‚§ãƒƒã‚¯
                    error_msg = None
                    if isinstance(transcription, tuple) and transcription[0] is None:
                        error_msg = transcription[1]
                        transcription = None
                        logger.error(f"ãƒã‚¤ã‚¯éŒ²éŸ³æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {error_msg}")
                    
                    if transcription:
                        # æ§‹é€ åŒ–å‡¦ç†
                        structured_data = None
                        tags = "ãƒã‚¤ã‚¯éŒ²éŸ³"
                        
                        if use_structuring and text_structurer:
                            with st.spinner("ãƒ†ã‚­ã‚¹ãƒˆæ§‹é€ åŒ–ä¸­..."):
                                structured_data = text_structurer.structure_text(transcription)
                                if structured_data:
                                    tags = text_structurer.extract_tags(structured_data)
                        
                        # çµæœã‚’ä¿å­˜
                        timestamp = datetime.now()
                        result = {
                            "ãƒ•ã‚¡ã‚¤ãƒ«å": f"ãƒã‚¤ã‚¯éŒ²éŸ³_{timestamp.strftime('%Y%m%d_%H%M%S')}.webm",
                            "éŒ²éŸ³æ™‚åˆ»": timestamp,
                            "éŒ²éŸ³æ™‚é–“": duration,
                            "æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ": transcription,
                            "æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿": structured_data,
                            "ã‚¿ã‚°": tags,
                            "ç™ºè¨€äººæ•°": 1
                        }
                        
                        st.session_state.transcriptions.append(result)
                        
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                        db = next(get_db())
                        try:
                            audio_record = AudioTranscription(
                                éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«path=result["ãƒ•ã‚¡ã‚¤ãƒ«å"],
                                ç™ºè¨€äººæ•°=1,
                                éŒ²éŸ³æ™‚åˆ»=timestamp,
                                éŒ²éŸ³æ™‚é–“=duration,
                                æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ=transcription,
                                æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿=structured_data,
                                ã‚¿ã‚°=tags
                            )
                            db.add(audio_record)
                            db.commit()
                            logger.info(f"ãƒã‚¤ã‚¯éŒ²éŸ³çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜: {result['ãƒ•ã‚¡ã‚¤ãƒ«å']}")
                            
                            # ãƒ™ã‚¯ãƒˆãƒ«DBã«è¿½åŠ 
                            try:
                                search_engine = get_semantic_search_engine()
                                doc_id = f"audio_{audio_record.éŸ³å£°ID}"
                                metadata = {
                                    "audio_id": audio_record.éŸ³å£°ID,
                                    "file_path": result["ãƒ•ã‚¡ã‚¤ãƒ«å"],
                                    "recording_time": timestamp.isoformat(),
                                    "duration": duration,
                                    "speakers": 1,
                                    "tags": tags or ""
                                }
                                if structured_data:
                                    metadata["structured_data"] = str(structured_data)
                                
                                search_engine.add_document(doc_id, transcription, metadata)
                                logger.info(f"Added to vector DB: {doc_id}")
                            except Exception as e:
                                logger.warning(f"Failed to add to vector DB: {str(e)}")
                                
                        finally:
                            db.close()
                        
                        # çµæœè¡¨ç¤º
                        st.success("âœ… æ–‡å­—èµ·ã“ã—å®Œäº†ï¼")
                        
                        col1, col2 = st.columns([1, 1])
                        with col1:
                            st.subheader("æ–‡å­—èµ·ã“ã—çµæœ")
                            st.text_area("", transcription, height=200, key="mic_transcription")
                            st.write(f"**éŒ²éŸ³æ™‚é–“:** {duration:.1f}ç§’")
                            st.write(f"**ã‚¿ã‚°:** {tags}")
                        
                        with col2:
                            if structured_data:
                                st.subheader("æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿")
                                st.json(structured_data)
                            else:
                                st.info("æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“")
                    
                    else:
                        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚‹å ´åˆã¯è©³ç´°ã‚’è¡¨ç¤º
                        if error_msg:
                            st.error(f"âŒ ãƒã‚¤ã‚¯éŒ²éŸ³ã®æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                            st.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {error_msg}")
                        else:
                            st.error("âŒ ãƒã‚¤ã‚¯éŒ²éŸ³ã®æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆçµæœãŒç©ºï¼‰")
                
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    os.unlink(tmp_path)
                    logger.debug(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {tmp_path}")
                    
                    # å‡¦ç†å®Œäº†å¾Œã€çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                    st.session_state.mic_processing = False
                    st.session_state.mic_audio_bytes = None
                    
            except Exception as e:
                error_msg = f"ãƒã‚¤ã‚¯éŒ²éŸ³å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}"
                st.error(error_msg)
                logger.error(error_msg, exc_info=True)
                st.session_state.mic_processing = False
    
    st.divider()
    st.markdown("**ğŸ’¡ ä½¿ã„æ–¹ã®ãƒ’ãƒ³ãƒˆ:**")
    st.markdown("- éŒ²éŸ³ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã‹ã‚‰è©±ã—ã¦ãã ã•ã„")
    st.markdown("- éŒ²éŸ³çµ‚äº†å¾Œã€ã€Œæ–‡å­—èµ·ã“ã—ã¦ä¿å­˜ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯")
    st.markdown("- éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã¯ä¸€æ™‚çš„ã«ä¿å­˜ã•ã‚Œã€å‡¦ç†å¾Œã«å‰Šé™¤ã•ã‚Œã¾ã™")

with tab3:
    st.header("å‡¦ç†çµæœ")
    
    if st.session_state.transcriptions:
        for idx, result in enumerate(st.session_state.transcriptions):
            with st.expander(f"ğŸ“ {result['ãƒ•ã‚¡ã‚¤ãƒ«å']}", expanded=True):
                col1, col2 = st.columns([1, 1])
                
                with col1:
                    st.subheader("åŸºæœ¬æƒ…å ±")
                    st.write(f"**éŒ²éŸ³æ™‚åˆ»:** {result['éŒ²éŸ³æ™‚åˆ»'].strftime('%Y/%m/%d %H:%M')}")
                    st.write(f"**éŒ²éŸ³æ™‚é–“:** {result['éŒ²éŸ³æ™‚é–“']:.1f}ç§’")
                    st.write(f"**ã‚¿ã‚°:** {result['ã‚¿ã‚°']}")
                    
                    st.subheader("æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ")
                    st.text_area("", result['æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ'], height=200, key=f"text_{idx}")
                
                with col2:
                    if result.get('æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿'):
                        st.subheader("æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿")
                        st.json(result['æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿'])
                    else:
                        st.info("æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“")
    else:
        st.info("å‡¦ç†çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å‡¦ç†ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")

with tab4:
    st.header("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…å®¹")
    
    # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢æ©Ÿèƒ½
    st.subheader("ğŸ” ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢")
    
    # æ¤œç´¢ã‚¿ãƒ–
    search_tab1, search_tab2, search_tab3 = st.tabs(["ğŸ¤– AIè³ªå•å¿œç­”", "ğŸ’­ æ„å‘³æ¤œç´¢", "ğŸ“‹ å…¨ãƒ¬ã‚³ãƒ¼ãƒ‰"])
    
    with search_tab1:
        st.subheader("ğŸ¤– AIè³ªå•å¿œç­”")
        st.markdown("**è­°äº‹éŒ²ã«é–¢ã™ã‚‹è³ªå•ã‚’è‡ªç„¶è¨€èªã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚AIãŒé–¢é€£ã™ã‚‹æƒ…å ±ã‚’æ¤œç´¢ã—ã¦å›ç­”ã—ã¾ã™ã€‚**")
        
        # è³ªå•å…¥åŠ›
        question = st.text_area(
            "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder="ä¾‹ï¼š\nãƒ»äºˆç®—å‰Šæ¸›ã«ã¤ã„ã¦ã“ã‚Œã¾ã§ã©ã®ã‚ˆã†ãªè­°è«–ãŒã‚ã‚Šã¾ã—ãŸã‹ï¼Ÿ\nãƒ»äººäº‹åˆ¶åº¦ã®è¦‹ç›´ã—ã§æ±ºã¾ã£ãŸã“ã¨ã‚’æ•™ãˆã¦ãã ã•ã„\nãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é€²æ—çŠ¶æ³ã¯ã©ã†ãªã£ã¦ã„ã¾ã™ã‹ï¼Ÿ",
            height=100,
            help="å…·ä½“çš„ã§æ˜ç¢ºãªè³ªå•ã»ã©ã€æ­£ç¢ºãªå›ç­”ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚"
        )
        
        # è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
        col1, col2, col3 = st.columns(3)
        with col1:
            max_sources = st.selectbox("å‚ç…§ã™ã‚‹è¨˜éŒ²æ•°", [3, 5, 8, 10], index=1)
        with col2:
            min_similarity = st.slider("é¡ä¼¼åº¦é–¾å€¤", 0.3, 0.9, 0.5, 0.1)
        with col3:
            show_sources = st.checkbox("å‚ç…§ã‚½ãƒ¼ã‚¹ã‚’è¡¨ç¤º", value=True)
        
        if question and question.strip():
            try:
                # RAGè³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã‚’å–å¾—
                rag_system = get_rag_qa_system()
                
                # è³ªå•å¿œç­”å®Ÿè¡Œ
                with st.spinner("ğŸ” é–¢é€£æƒ…å ±ã‚’æ¤œç´¢ã—ã¦AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                    result = rag_system.answer_question(
                        question=question.strip(),
                        max_context_docs=max_sources,
                        min_similarity=min_similarity
                    )
                
                # å›ç­”è¡¨ç¤º
                st.markdown("### ğŸ’¬ AIå›ç­”")
                
                # ä¿¡é ¼åº¦ã«å¿œã˜ã¦ã‚¹ã‚¿ã‚¤ãƒ«å¤‰æ›´
                confidence = result.get('confidence', 0.0)
                if confidence >= 0.7:
                    st.success("ğŸ¯ é«˜ä¿¡é ¼åº¦ã®å›ç­”")
                elif confidence >= 0.5:
                    st.info("ğŸ“ ä¸­ç¨‹åº¦ã®ä¿¡é ¼åº¦")
                else:
                    st.warning("âš ï¸ ä½ä¿¡é ¼åº¦ï¼ˆå‚è€ƒç¨‹åº¦ï¼‰")
                
                # å›ç­”æœ¬æ–‡
                st.markdown(result['answer'])
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
                metadata = result.get('metadata', {})
                col_meta1, col_meta2, col_meta3 = st.columns(3)
                with col_meta1:
                    st.metric("ä¿¡é ¼åº¦", f"{confidence:.1%}")
                with col_meta2:
                    st.metric("æ¤œç´¢ä»¶æ•°", metadata.get('search_count', 0))
                with col_meta3:
                    st.metric("å‚ç…§è¨˜éŒ²", len(result.get('sources', [])))
                
                # å‚ç…§ã‚½ãƒ¼ã‚¹è¡¨ç¤º
                if show_sources and result.get('sources'):
                    st.markdown("### ğŸ“š å‚ç…§ã—ãŸéŸ³å£°è¨˜éŒ²")
                    
                    for i, source in enumerate(result['sources'], 1):
                        with st.expander(f"ğŸ“„ éŸ³å£°è¨˜éŒ² {i} - ID {source.get('audio_id', 'Unknown')} (é¡ä¼¼åº¦: {source.get('similarity_score', 0):.3f})"):
                            col_src1, col_src2 = st.columns(2)
                            
                            with col_src1:
                                st.markdown(f"**ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«:** {source.get('file_path', 'N/A')}")
                                recording_time = source.get('recording_time', '')
                                if recording_time:
                                    st.markdown(f"**ğŸ“… éŒ²éŸ³æ™‚åˆ»:** {recording_time[:19]}")
                            
                            with col_src2:
                                st.markdown(f"**ğŸ¯ é¡ä¼¼åº¦:** {source.get('similarity_score', 0):.3f}")
                            
                            st.markdown("**ğŸ“ å†…å®¹:**")
                            st.write(source.get('excerpt', ''))
                
                # ã‚¨ãƒ©ãƒ¼æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
                if 'error' in metadata:
                    st.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {metadata['error']}")
                    
            except Exception as e:
                st.error(f"è³ªå•å¿œç­”ã‚¨ãƒ©ãƒ¼: {str(e)}")
                logger.error(f"RAG QA error: {str(e)}")
        
        elif question and not question.strip():
            st.info("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        
        # ä½¿ã„æ–¹ã®ãƒ’ãƒ³ãƒˆ
        st.markdown("---")
        st.markdown("**ğŸ’¡ ä½¿ã„æ–¹ã®ã‚³ãƒ„:**")
        st.markdown("- å…·ä½“çš„ãªè³ªå•ã»ã©æ­£ç¢ºãªå›ç­”ãŒå¾—ã‚‰ã‚Œã¾ã™")
        st.markdown("- ã€Œã„ã¤ã€ã€Œèª°ãŒã€ã€Œä½•ã‚’ã€ã‚’å«ã‚ã‚‹ã¨åŠ¹æœçš„ã§ã™")
        st.markdown("- è¤‡æ•°ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’ä¸€åº¦ã«èãã‚ˆã‚Šã€å€‹åˆ¥ã«è³ªå•ã—ã¦ãã ã•ã„")

    with search_tab2:
        st.subheader("ğŸ’­ æ„å‘³æ¤œç´¢")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            search_query = st.text_input(
                "æ¤œç´¢ã—ãŸã„å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                placeholder="ä¾‹: äºˆç®—å‰Šæ¸›ã«ã¤ã„ã¦ã€äººäº‹åˆ¶åº¦ã®è¦‹ç›´ã—ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é€²æ—çŠ¶æ³",
                help="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã ã‘ã§ãªãã€æ–‡ç« ã§ã‚‚æ¤œç´¢ã§ãã¾ã™ã€‚æ„å‘³ãŒä¼¼ã¦ã„ã‚‹å†…å®¹ã‚‚è‡ªå‹•ã§è¦‹ã¤ã‘ã¾ã™ã€‚"
            )
        
        with col2:
            search_limit = st.selectbox("è¡¨ç¤ºä»¶æ•°", [5, 10, 20, 50], index=1, key="semantic_search_limit")
        
        if search_query:
            try:
                # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’å–å¾—
                search_engine = get_semantic_search_engine()
                
                # ãƒ™ã‚¯ãƒˆãƒ«DBã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
                stats = search_engine.get_collection_stats()
                if stats.get("total_documents", 0) == 0:
                    st.warning("âš ï¸ ãƒ™ã‚¯ãƒˆãƒ«DBã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æ–‡å­—èµ·ã“ã—ã—ã¦ã€ãƒ™ã‚¯ãƒˆãƒ«DBã¨åŒæœŸã—ã¦ãã ã•ã„ã€‚")
                    st.info("ğŸ’¡ éŸ³å£°ã‚’éŒ²éŸ³ãƒ»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€è‡ªå‹•çš„ã«ãƒ™ã‚¯ãƒˆãƒ«DBã«è¿½åŠ ã•ã‚Œã¾ã™ã€‚")
                else:
                    # æ¤œç´¢å®Ÿè¡Œ
                    with st.spinner("æ¤œç´¢ä¸­..."):
                        results = search_engine.search(search_query, n_results=search_limit)
                    
                    if results:
                        st.success(f"ğŸ¯ {len(results)}ä»¶ã®çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
                        
                        for i, result in enumerate(results, 1):
                            metadata = result['metadata']
                            similarity = result['similarity_score']
                            
                            # çµæœã‚’è¡¨ç¤º
                            with st.expander(f"#{i} éŸ³å£°ID {metadata.get('audio_id', 'Unknown')} (é¡ä¼¼åº¦: {similarity:.3f})"):
                                st.markdown(f"**ğŸ“„ æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ:**")
                                st.write(result['document'])
                                
                                col_meta1, col_meta2 = st.columns(2)
                                with col_meta1:
                                    st.markdown(f"**ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«:** {metadata.get('file_path', 'N/A')}")
                                    st.markdown(f"**ğŸ™ï¸ ç™ºè¨€äººæ•°:** {metadata.get('speakers', 'N/A')}")
                                
                                with col_meta2:
                                    recording_time = metadata.get('recording_time', '')
                                    if recording_time:
                                        st.markdown(f"**ğŸ“… éŒ²éŸ³æ™‚åˆ»:** {recording_time[:19]}")  # ISOå½¢å¼ã®æ—¥æ™‚ã‹ã‚‰ç§’ã¾ã§è¡¨ç¤º
                                    st.markdown(f"**â±ï¸ éŒ²éŸ³æ™‚é–“:** {metadata.get('duration', 'N/A')}ç§’")
                                
                                # ã‚¿ã‚°ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
                                tags = metadata.get('tags', '')
                                if tags:
                                    st.markdown(f"**ğŸ·ï¸ ã‚¿ã‚°:** {tags}")
                    else:
                        st.info("è©²å½“ã™ã‚‹çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
                        
            except Exception as e:
                st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
                logger.error(f"Semantic search error: {str(e)}")
    
    with search_tab3:
        st.subheader("ğŸ“‹ å…¨ãƒ¬ã‚³ãƒ¼ãƒ‰ä¸€è¦§")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å…¨ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
        db = next(get_db())
        try:
            records = db.query(AudioTranscription).all()
            
            if records:
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
                data = []
                for record in records:
                    data.append({
                        "éŸ³å£°ID": record.éŸ³å£°ID,
                        "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«": record.éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«path,
                        "ç™ºè¨€äººæ•°": record.ç™ºè¨€äººæ•°,
                        "éŒ²éŸ³æ™‚åˆ»": record.éŒ²éŸ³æ™‚åˆ»,
                        "éŒ²éŸ³æ™‚é–“(s)": record.éŒ²éŸ³æ™‚é–“,
                        "ã‚¿ã‚°": record.ã‚¿ã‚°,
                        "æ–‡å­—èµ·ã“ã—": record.æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ[:50] + "..." if len(record.æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ) > 50 else record.æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ
                    })
                
                df = pd.DataFrame(data)
                
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                col1, col2 = st.columns([1, 1])
                with col1:
                    tag_filter = st.selectbox("ã‚¿ã‚°ã§ãƒ•ã‚£ãƒ«ã‚¿", ["ã™ã¹ã¦"] + list(df["ã‚¿ã‚°"].unique()))
                
                if tag_filter != "ã™ã¹ã¦":
                    df = df[df["ã‚¿ã‚°"] == tag_filter]
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
                st.dataframe(df, use_container_width=True)
                
                # è©³ç´°è¡¨ç¤º
                if st.checkbox("è©³ç´°ã‚’è¡¨ç¤º"):
                    selected_id = st.selectbox("éŸ³å£°IDã‚’é¸æŠ", df["éŸ³å£°ID"].tolist())
                    
                    if selected_id:
                        record = db.query(AudioTranscription).filter_by(éŸ³å£°ID=selected_id).first()
                        if record:
                            st.subheader(f"éŸ³å£°ID: {record.éŸ³å£°ID} ã®è©³ç´°")
                            
                            col1, col2 = st.columns([1, 1])
                            with col1:
                                st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«:** {record.éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«path}")
                                st.write(f"**éŒ²éŸ³æ™‚åˆ»:** {record.éŒ²éŸ³æ™‚åˆ»}")
                                st.write(f"**éŒ²éŸ³æ™‚é–“:** {record.éŒ²éŸ³æ™‚é–“}ç§’")
                                st.write(f"**ã‚¿ã‚°:** {record.ã‚¿ã‚°}")
                                
                                st.subheader("æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ")
                                st.text_area("", record.æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ, height=200)
                            
                            with col2:
                                if record.æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿:
                                    st.subheader("æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿")
                                    st.json(record.æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿)
            else:
                st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        finally:
            db.close()

# ãƒ•ãƒƒã‚¿ãƒ¼
st.divider()
st.markdown("ğŸ™ï¸ éŸ³å£°æ–‡å­—èµ·ã“ã—Webã‚¢ãƒ—ãƒª v1.0")